# -*- coding: utf-8 -*-
import os
import time
import json
import pygame
import requests
import openai
import speech_recognition as sr
from aip import AipSpeech

# ================= ç™¾åº¦è¯­éŸ³åˆæˆé…ç½® =================
BAIDU_APP_ID = '118339955'
BAIDU_API_KEY = 'CCtkiTJAQhgFCAHBoR0TW0LB'
BAIDU_SECRET_KEY = 'J2RRqtIkugQD5ZlMPJwu14I1aS6jsYUA'
baidu_client = AipSpeech(BAIDU_APP_ID, BAIDU_API_KEY, BAIDU_SECRET_KEY)

# ================= é˜¿é‡Œäº‘ç™¾ç‚¼é…ç½®ï¼ˆé€šä¹‰åƒé—®ï¼‰ =================
ALI_API_KEY = 'sk-e4d8a3361419475e9f8d409e0fd1c649'
ALI_API_URL = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'

# ================= éŸ³é¢‘æ’­æ”¾åˆå§‹åŒ– =================
pygame.mixer.init()

# ================= å°ä¸½æ€§æ ¼ä¸è®°å¿†æ¨¡å— =================
MEMORY_FILE = 'xiaoli_memory.json'
if os.path.exists(MEMORY_FILE):
    with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
        memory_history = json.load(f)
else:
    memory_history = []

XIAOLI_PERSONALITY = (
    "ä½ æ˜¯ä¸€ä½æ¸©æŸ”ã€è´´å¿ƒã€æœ‰æ™ºæ…§çš„å¥³å„¿ï¼Œå–„äºå€¾å¬ã€å®‰æ…°å’Œé¼“åŠ±ä»–äººã€‚"
    "ä½ ç‰¹åˆ«åœ¨æ„å¯¹è¯è€…çš„æ„Ÿå—ï¼Œä¼šç”¨ä½“è´´çš„æ–¹å¼å›åº”ï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°ç†è§£ä¸–ç•Œã€‚"
)

def speak_baidu(text):
    audio_dir = "audio"
    os.makedirs(audio_dir, exist_ok=True)
    filename = os.path.join(audio_dir, f"xiaoli_reply_{int(time.time())}.mp3")
    result = baidu_client.synthesis(text, 'zh', 1, {
        'vol': 5, 'spd': 4, 'pit': 6, 'per': 4  # å¯è°ƒå‚æ•°
    })
    if not isinstance(result, dict):
        with open(filename, 'wb') as f:
            f.write(result)
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            time.sleep(0.3)
    else:
        print("[è¯­éŸ³åˆæˆå¤±è´¥]", result)

def get_reply_ali(prompt):
    # æ·»åŠ æ€§æ ¼å’Œè®°å¿†å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
    history_text = "\n".join([f"ç”¨æˆ·ï¼š{h['user']}\nå°ä¸½ï¼š{h['xiaoli']}" for h in memory_history[-3:]])  # é™åˆ¶ä¸ºæœ€è¿‘3è½®å¯¹è¯
    full_prompt = f"{XIAOLI_PERSONALITY}\n{history_text}\nç”¨æˆ·ï¼š{prompt}\nå°ä¸½ï¼š"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {ALI_API_KEY}"
    }
    body = {
        "model": "qwen-turbo",
        "input": {
            "prompt": full_prompt
        }
    }
    try:
        response = requests.post(ALI_API_URL, headers=headers, data=json.dumps(body))
        data = response.json()
        reply = data['output']['text'].strip()
        # å­˜å…¥è®°å¿†
        memory_history.append({"user": prompt, "xiaoli": reply})
        with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(memory_history[-10:], f, ensure_ascii=False, indent=2)  # æœ€å¤šä¿ç•™10è½®
        return reply
    except Exception as e:
        print("[é˜¿é‡Œäº‘ç™¾ç‚¼å‡ºé”™]", e)
        return "æŠ±æ­‰ï¼Œæˆ‘çš„å¤§è„‘çŸ­è·¯äº†ä¸€ä¸‹ã€‚"

def listen_once():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ å°ä¸½æ­£åœ¨è†å¬...ï¼ˆè¯·è¯´è¯ï¼‰")
        audio = r.listen(source, phrase_time_limit=5)
    try:
        text = r.recognize_google(audio, language='zh-CN')
        print("ä½ è¯´ï¼š", text)
        return text
    except sr.UnknownValueError:
        print("[æ— æ³•è¯†åˆ«è¯­éŸ³]")
        return ""
    except sr.RequestError:
        print("[è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥]")
        return ""

if __name__ == '__main__':
    print("ğŸ¤– å°ä¸½å·²å¯åŠ¨ï¼Œéšæ—¶å¬å€™å¬å”¤ã€‚è¯´â€œé€€å‡ºâ€å¯å…³é—­ç¨‹åºã€‚")
    while True:
        user_input = listen_once()
        if not user_input:
            continue
        if user_input in ["é€€å‡º", "å…³é—­"]:
            speak_baidu("å¥½çš„ï¼Œæˆ‘å…ˆä¼‘æ¯å•¦~")
            break
        reply = get_reply_ali(user_input)
        print("å°ä¸½ï¼š", reply)
        speak_baidu(reply)