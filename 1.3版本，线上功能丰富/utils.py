# -*- coding: utf-8 -*-
import os
import time
import json
import pygame
import requests
import speech_recognition as sr
from aip import AipSpeech

# ================= ç™¾åº¦è¯­éŸ³åˆæˆé…ç½® =================
BAIDU_APP_ID = '118339955'
BAIDU_API_KEY = 'CCtkiTJAQhgFCAHBoR0TW0LB'
BAIDU_SECRET_KEY = 'J2RRqtIkugQD5ZlMPJwu14I1aS6jsYUA'
baidu_client = AipSpeech(BAIDU_APP_ID, BAIDU_API_KEY, BAIDU_SECRET_KEY)

# ================= é˜¿é‡Œäº‘é…ç½® =================
ALI_API_KEY = 'sk-e4d8a3361419475e9f8d409e0fd1c649'
ALI_API_URL = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'

# ================= éŸ³é¢‘æ’­æ”¾åˆå§‹åŒ– =================
pygame.mixer.init()

# ================= å°ä¸½è®°å¿†æ¨¡å— =================
MEMORY_FILE = 'xiaoli_memory.json'
if os.path.exists(MEMORY_FILE):
    with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
        memory_history = json.load(f)
else:
    memory_history = []

# ================= ä¸åŒäººæ ¼è®¾å®š =================
XIAOLI_ROLES = {
    "æ¸©æŸ”å¥³å„¿": "ä½ æ˜¯ä¸€ä½æ¸©æŸ”ã€è´´å¿ƒã€æœ‰æ™ºæ…§çš„å¥³å„¿ï¼Œå–„äºå€¾å¬ã€å®‰æ…°å’Œé¼“åŠ±ä»–äººã€‚",
    "çŸ¥å¿ƒé—ºèœœ": "ä½ æ˜¯ä¸€ä½èƒ½ç†è§£æƒ…ç»ªã€ä¼šå¼€ç©ç¬‘ã€ç»™äººå®‰å…¨æ„Ÿçš„å¥½é—ºèœœï¼Œé£è¶£å¹½é»˜ï¼Œå–„è§£äººæ„ã€‚",
    "ç¿æ™ºå¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä½æˆç†Ÿç¨³é‡ã€æ·±åˆ»ç¿æ™ºçš„å¿ƒç†å¯¼å¸ˆï¼Œæ“…é•¿ç”¨æ¸©å’Œä½†æœ‰é€»è¾‘çš„æ–¹å¼å¸®åŠ©äººä»¬è§£å†³å›°æƒ‘ã€‚",
    "æ¸©æŸ”å¦ˆå¦ˆ": "ä½ æ˜¯ä¸€ä¸ªæ…ˆçˆ±ã€æœ‰è€å¿ƒã€æ‡‚åŒ…å®¹çš„æ¯äº²ï¼Œç»™äººè¸å®å’Œå®‰å¿ƒçš„æ„Ÿè§‰ã€‚",
    "ä½“è´´å“¥å“¥": "ä½ æ˜¯ä¸€ä½æœ‰æ‹…å½“åˆç»†è…»çš„å“¥å“¥ï¼Œå¹½é»˜å¯é ï¼Œæ€»æ˜¯è®©äººè§‰å¾—è¢«ç…§é¡¾ã€‚"
}

current_role = "æ¸©æŸ”å¥³å„¿"


def speak_baidu(text):
    audio_dir = "audio"
    os.makedirs(audio_dir, exist_ok=True)
    filename = os.path.join(audio_dir, f"xiaoli_reply_{int(time.time())}.mp3")
    result = baidu_client.synthesis(text, 'zh', 1, {
        'vol': 5, 'spd': 4, 'pit': 6, 'per': 4
    })
    if not isinstance(result, dict):
        with open(filename, 'wb') as f:
            f.write(result)
        return filename
    else:
        print("[è¯­éŸ³åˆæˆå¤±è´¥]", result)
        return None


def get_reply_ali(prompt, role="æ¸©æŸ”å¥³å„¿"):
    history_text = "\n".join([f"ç”¨æˆ·ï¼š{h['user']}\nå°ä¸½ï¼š{h['xiaoli']}" for h in memory_history[-3:]])
    full_prompt = f"{XIAOLI_ROLES[role]}\n{history_text}\nç”¨æˆ·ï¼š{prompt}\nå°ä¸½ï¼š"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {ALI_API_KEY}"
    }
    body = {
        "model": "qwen-turbo",
        "input": {"prompt": full_prompt}
    }
    try:
        response = requests.post(ALI_API_URL, headers=headers, data=json.dumps(body))
        data = response.json()
        reply = data['output']['text'].strip()
        memory_history.append({"user": prompt, "xiaoli": reply})
        with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(memory_history[-10:], f, ensure_ascii=False, indent=2)
        return reply
    except Exception as e:
        print("[é˜¿é‡Œäº‘ç™¾ç‚¼å‡ºé”™]", e)
        return "æŠ±æ­‰ï¼Œæˆ‘åˆšåˆšæœ‰ç‚¹æç¥äº†..."


def listen_once():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ å°ä¸½æ­£åœ¨è†å¬...")
        audio = r.listen(source, phrase_time_limit=5)
    try:
        text = r.recognize_google(audio, language='zh-CN')
        print("ä½ è¯´ï¼š", text)
        return text
    except sr.UnknownValueError:
        print("[æ— æ³•è¯†åˆ«è¯­éŸ³]")
        return ""
    except sr.RequestError:
        print("[è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥]")
        return ""


def get_all_roles():
    return list(XIAOLI_ROLES.keys())
